{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d4e5cb-9d39-4e59-98c1-32be6d89f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os, glob, pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d8c735-9436-416a-8e27-0cd63100e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myClassifier = pickle.load(open('speechemotionclassifier' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fada5ad-2861-43f7-a6ad-3ac913b09820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with sf.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ab52d4-91b6-4790-ae43-bfd77a2bd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyaudio\n",
    "# import wave\n",
    "  \n",
    "# FORMAT = pyaudio.paInt16\n",
    "# CHANNELS = 2\n",
    "# RATE = 44100\n",
    "# CHUNK = 1024\n",
    "# RECORD_SECONDS = 5\n",
    "# WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    "  \n",
    "# audio = pyaudio.PyAudio()\n",
    "  \n",
    "# # start Recording\n",
    "# stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "#                 rate=RATE, input=True,\n",
    "#                 frames_per_buffer=CHUNK)\n",
    "# print (\"recording...\")\n",
    "# frames = []\n",
    "  \n",
    "# for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "#     data = stream.read(CHUNK)\n",
    "#     frames.append(data)\n",
    "# print (\"finished recording\")\n",
    "  \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# stream.stop_stream()\n",
    "# stream.close()\n",
    "# audio.terminate()\n",
    "  \n",
    "# waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "# waveFile.setnchannels(CHANNELS)\n",
    "# waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "# waveFile.setframerate(RATE)\n",
    "# waveFile.writeframes(b''.join(frames))\n",
    "# waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c590a3-e4aa-46a6-b541-a61d0f8848ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soundfile = \"file.wav\"\n",
    "# type(soundfile)\n",
    "\n",
    "# # print(f\"Valid audio {librosa.util.valid_audio(soundfile, mono=True)}\")\n",
    "# feature = extract_feature(soundfile, mfcc=True, chroma=True, mel=True)\n",
    "# xpred = np.array(feature)\n",
    "# pred = xpred.reshape(1,-1)\n",
    "# print(f\"Valid audio {librosa.util.valid_audio(data, mono=True)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a974e0d-8975-4848-ac45-cedd0e794e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 program to illustrate\n",
    "# splitting stereo audio to mono\n",
    "# using pydub\n",
    "\n",
    "# Import AudioSegment from pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Open the stereo audio file as\n",
    "# an AudioSegment instance\n",
    "stereo_audio = AudioSegment.from_file(\"file.wav\",format=\"wav\")\n",
    "\n",
    "# Calling the split_to_mono method\n",
    "# on the stereo audio file\n",
    "mono_audios = stereo_audio.split_to_mono()\n",
    " \n",
    "# Exporting/Saving the two mono\n",
    "# audio files present at index 0(left)\n",
    "# and index 1(right) of list returned\n",
    "# by split_to_mono method\n",
    "mono_left = mono_audios[0].export(\"predictemotion.wav\",format=\"wav\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5e133e-721b-4a2d-bc51-6add44f6b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 180)\n"
     ]
    }
   ],
   "source": [
    "# soundfile = \"NewDataset/Sad/sa2.wav\"\n",
    "soundfile = \"f03.wav\"\n",
    "feature = extract_feature(soundfile, mfcc=True, chroma=True, mel=True)\n",
    "xpred = np.array(feature.reshape(1, -1))\n",
    "print(xpred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b826345-63c8-4345-ba46-ad2779ac4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = myClassifier.predict(xpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884e59e1-241b-4f39-b0fb-dcf7740ee6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted the emotion as ['Fear']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted the emotion as {str(res)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
